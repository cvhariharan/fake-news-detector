Google has started rolling out visual search feature Google Lens in Assistant for the first batch of Pixel and Pixel 2 smartphones. “The first users have spotted the visual search feature up and running on their Pixel and Pixel 2 phones,” 9to5Google reported late on Friday.Built into the Photos app, Google Lens can recognise things like addresses and books, among others. In Photos, the feature can be activated when viewing any image or screenshot. Even if a user has the camera on, the AI helper can create searches around objects and text in the frame.However, in Google Assistant, it is integrated right into the sheet that pops up after holding down on the home button. The Lens is a feature that users can rate based on their experiences and search results, which can refine searches for future users.